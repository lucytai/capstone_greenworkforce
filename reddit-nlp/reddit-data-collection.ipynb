{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78246874-10a3-479e-9f8b-5d15e0b74e04",
   "metadata": {},
   "source": [
    "# Reddit Scraping of Trades and Technical Career Conversations: Plugging the Net Zero Skills Gap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b8f47-1c58-4f96-94a1-d5750be9a5e5",
   "metadata": {},
   "source": [
    "## Data collection: Subreddit scraping of key words\n",
    "\n",
    "### Using the PRAW Reddit API Wrapper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a434cdee-86a1-478c-b6c1-4fd460d322d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize Reddit instance\n",
    "reddit = praw.Reddit(client_id='muPXdjidIpixFPsyGmoA7g',\n",
    "                     client_secret='XGMBm0LWjxP6-l2A8C4jy6BvMK-rPw',\n",
    "                     user_agent='capstone-greenjobs')\n",
    "\n",
    "# Define the list of relevant subreddits\n",
    "subreddits = ['careerguidance', 'career_advice', 'findapath']\n",
    "\n",
    "# Define the list of relevant keywords and phrases\n",
    "keywords = ['technician','blue collar','trade school','skilled trade', 'electrician','plumber',\n",
    "            'green construction','wind technician', 'solar installer']\n",
    "\n",
    "# Set the minimum length for a comment to be considered relevant\n",
    "min_comment_length = 50\n",
    "\n",
    "# Set the minimum score for a post or comment to be considered relevant\n",
    "min_score = 1\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each subreddit\n",
    "for sub in subreddits:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    \n",
    "    # Search for submissions containing the keywords\n",
    "    for keyword in keywords:\n",
    "        submissions = subreddit.search(keyword, limit=20, time_filter='year')\n",
    "        \n",
    "        # Loop through each submission\n",
    "        for submission in submissions:\n",
    "            # Extract information from the submission\n",
    "            submission_data = {\n",
    "                'subreddit': sub,\n",
    "                'keyword': keyword,\n",
    "                'type': 'post',\n",
    "                'post_id': submission.id,\n",
    "                'title': submission.title,\n",
    "                'text': submission.selftext,\n",
    "                'score': submission.score,\n",
    "                'created_utc': submission.created_utc,\n",
    "            }\n",
    "            \n",
    "            # Append the submission data to the main data list\n",
    "            data.append(submission_data)\n",
    "            \n",
    "            # Extract comments from the submission\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            for comment in submission.comments.list():\n",
    "                comment_text = comment.body\n",
    "\n",
    "                # Check if the comment meets the minimum length and score requirements\n",
    "                if len(comment_text) >= min_comment_length and comment.score >= min_score:\n",
    "                    comment_data = {\n",
    "                        'subreddit': sub,\n",
    "                        'keyword': keyword,\n",
    "                        'type': 'comment',\n",
    "                        'post_id': submission.id,\n",
    "                        'comment_id': comment.id,\n",
    "                        'text': comment_text,\n",
    "                        'score': comment.score,\n",
    "                        'created_utc': comment.created_utc,\n",
    "                    }\n",
    "\n",
    "                    # Append the comment data to the main data list\n",
    "                    data.append(comment_data)\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('reddit_data_nlp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05408c91-f217-4ec1-8962-aabcc7568bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        subreddit     keyword     type  post_id  \\\n",
      "0  careerguidance  technician     post  1bfsfa4   \n",
      "1  careerguidance  technician  comment  1bfsfa4   \n",
      "2  careerguidance  technician  comment  1bfsfa4   \n",
      "3  careerguidance  technician  comment  1bfsfa4   \n",
      "4  careerguidance  technician  comment  1bfsfa4   \n",
      "\n",
      "                                               title  \\\n",
      "0  I’m the only technician left and I’m underpaid...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                                text  score   created_utc  \\\n",
      "0  I’m getting a pay raise and my only coworker i...    101  1.710547e+09   \n",
      "1  Do you feel fairly confident that you can get ...    102  1.710548e+09   \n",
      "2  1. State that with \"Joe\" leaving, you know tha...     69  1.710548e+09   \n",
      "3  There is nothing like negotiating when you hol...     37  1.710549e+09   \n",
      "4  I would apply and interview at a few places an...     20  1.710551e+09   \n",
      "\n",
      "  comment_id  \n",
      "0        NaN  \n",
      "1    kv2lho1  \n",
      "2    kv2mjbg  \n",
      "3    kv2psvn  \n",
      "4    kv2tlw1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('reddit_data_nlp.csv')\n",
    "# Display the first few rows of the DataFrame to verify the data\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f87d1-28ce-4117-a879-ed09ed429577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# White collar\n",
    "\n",
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize Reddit instance\n",
    "reddit = praw.Reddit(client_id='muPXdjidIpixFPsyGmoA7g',\n",
    "                     client_secret='XGMBm0LWjxP6-l2A8C4jy6BvMK-rPw',\n",
    "                     user_agent='capstone-greenjobs')\n",
    "\n",
    "# Define the list of relevant subreddits\n",
    "subreddits = ['careerguidance', 'career_advice', 'findapath']\n",
    "\n",
    "# Define the list of relevant keywords and phrases\n",
    "keywords = ['university','college degree',\"bachelor's degree\", 'higher education', 'white-collar', 'corporate']\n",
    "\n",
    "# Set the minimum length for a comment to be considered relevant\n",
    "min_comment_length = 50\n",
    "\n",
    "# Set the minimum score for a post or comment to be considered relevant\n",
    "min_score = 1\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each subreddit\n",
    "for sub in subreddits:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    \n",
    "    # Search for submissions containing the keywords\n",
    "    for keyword in keywords:\n",
    "        submissions = subreddit.search(keyword, limit=20, time_filter='year')\n",
    "        \n",
    "        # Loop through each submission\n",
    "        for submission in submissions:\n",
    "            # Extract information from the submission\n",
    "            submission_data = {\n",
    "                'subreddit': sub,\n",
    "                'keyword': keyword,\n",
    "                'type': 'post',\n",
    "                'post_id': submission.id,\n",
    "                'title': submission.title,\n",
    "                'text': submission.selftext,\n",
    "                'score': submission.score,\n",
    "                'created_utc': submission.created_utc,\n",
    "            }\n",
    "            \n",
    "            # Append the submission data to the main data list\n",
    "            data.append(submission_data)\n",
    "            \n",
    "            # Extract comments from the submission\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            for comment in submission.comments.list():\n",
    "                comment_text = comment.body\n",
    "\n",
    "                # Check if the comment meets the minimum length and score requirements\n",
    "                if len(comment_text) >= min_comment_length and comment.score >= min_score:\n",
    "                    comment_data = {\n",
    "                        'subreddit': sub,\n",
    "                        'keyword': keyword,\n",
    "                        'type': 'comment',\n",
    "                        'post_id': submission.id,\n",
    "                        'comment_id': comment.id,\n",
    "                        'text': comment_text,\n",
    "                        'score': comment.score,\n",
    "                        'created_utc': comment.created_utc,\n",
    "                    }\n",
    "\n",
    "                    # Append the comment data to the main data list\n",
    "                    data.append(comment_data)\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv('reddit_data_nlp_white_collar.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d173f-2b5a-4fc9-a2ea-3098c2515c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('reddit_data_nlp_white_collar.csv')\n",
    "# Display the first few rows of the DataFrame to verify the data\n",
    "print(df.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
